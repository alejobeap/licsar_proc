#!/usr/bin/env python
import sys
import os
import shutil
import datetime
import ntpath
import getopt
import re
import numpy as np
try:
  import py_gamma as pg
except ImportError as e:
  if 'py_gamma' in str(e):
    print('\nERROR: cannot load py_gamma.py')
    print('       setting the environmental variable "PYTHONPATH" in your .bashrc as follows may solve the issue:')
    print('       export PYTHONPATH=.:$GAMMA_HOME:$PYTHONPATH\n')
  else:
    print('\nERROR: ' + str(e))
  sys.exit()

def usage():
  print("""
usage: ScanSAR_coreg.py <SLC1_tab> <SLC1_ID> <SLC2_tab> <SLC2_ID> <RSLC2_tab> [hgt] [rlks] [azlks] [options]
    SLC1_tab      (input) SLC_tab of ScanSAR burst SLC reference (e.g. 20200208.SLC_tab)
    SLC1_ID       ID for reference files (e.g. 20200208)
    SLC2_tab      (input) SLC_tab of ScanSAR burst SLC second scene (e.g. 20200224.SLC_tab)
    SLC2_ID       ID for second scene files (e.g. 20200224)
    RSLC2_tab     (input) SLC_tab of co-registered ScanSAR burst SLC second scene (e.g. 20200224.RSLC_tab)
                  NOTE: if RSLC2_tab does not yet exist, the file entries will be created with names based on SLC2_tab
    hgt           (input) height map in RDC of MLI-1 mosaic (float, or constant height value; enter - for default: 0.1)
    rlks          number of range looks in the output MLI image (enter - for default: 10)
    azlks         number of azimuth looks in the output MLI image (enter - for default: 2)
    
    --poly1 file        (input) polygon file indicating area used for intensity matching (relative to MLI reference)
    --poly2 file        (input) polygon file indicating area used for spectral diversity (relative to MLI reference)
    --cc value          coherence threshold used (default: 0.8)
    --fraction value    minimum valid fraction of unwrapped phase values used (default: 0.01)
    --ph_stdev value    phase standard deviation threshold (default: 0.8 radian)
    --it1 number        maximum number of iterations in intensity matching method (enter 0 to skip method, default: 5)
    --it2 number        maximum number of iterations in spectral diversity method (enter 0 to skip method, default: 5)
    --num_ovr number    maximum number of successful burst overlap measurements per subswath (enter 0 for all, default: 10)
    --npoly number      number of model polynomial parameters (1, 3, 4 or 6, default: 1)
    --nr number         number of offset estimates in range direction in intensity matching (default: 64)
    --naz number        number of offset estimates in azimuth direction in intensity matching (default: 64)
    --rwin number       range patch size in intensity matching (default: 256)
    --azwin number      azimuth patch size in intensity matching (default: 256)
    --RSLC3_tab file    (input) 3 column list of already co-registered ScanSAR second scene to use for overlap interferograms
    --RSLC3_ID name     ID for already co-registered ScanSAR second scene; an interferogram between RSLC3 and RSLC2 is calculated
    --lt1 name          (input) modified lookup table (generated by adding an offset field to the orbit based lookup table)
    --wdir path         path to working directory; the working directory will be created if it doesn't exist (default: .)
    --no_check          do not check if second scene data correspond to reference data
    --no_int            no interferogram will be generated at the end of the coregistration process
    --no_cleaning       keep intermediate files
    --use_existing      use existing intermediate files
    --ignore_errors     continue processing when errors are detected
  """)
  print("Python version: " + sys.version)
  sys.exit()

def check_output(status, error_flag, cleaning, tmp_dir):
  if (status != 0 and error_flag == 0):
    print("\nERROR in previous command\n")
    
    if cleaning:
      try:
        shutil.rmtree(tmp_dir)
      except OSError:
        print("\nDeletion of the directory %s failed" % tmp_dir)
      else:
        print("\nSuccessfully deleted the directory %s" % tmp_dir)
    
    sys.exit(-1)

def main():
  print('*** ScanSAR_coreg.py: Script to coregister a ScanSAR or TOPS mode burst SLC to a reference burst SLC ***')
  print('*** Copyright 2022 Gamma Remote Sensing, v3.7 25-May-2022 cm/uw ***')
  
  # init values
  t_cur = datetime.datetime.now()
  tmp_dir = 'tmp_dir_coreg_' + str(int(t_cur.hour)) + str(int(t_cur.minute)) + str(int(t_cur.second)) + str(int(t_cur.microsecond))
  cleaning = 1            # 0: no, 1: yes
  hgt_name = '-'
  hgt_file_flag = 0       # flag indicating if height file exists (0: no, 1: yes)
  hgt_val = 0.1
  flag1 = 0
  error_flag = 0
  rlks = 10
  azlks = 2
  cc_thresh = 0.8
  fraction_thresh = 0.01
  stdev_thresh = 0.8      # phase offset estimation standard deviation in a burst overlap region in radian
  max_num_ovr = 10
  poly1_flag = 0
  poly2_flag = 0
  RSLC3_flag = 0
  poly1_name = '-'
  poly2_name = '-'
  poly_mask_flag = 1
  ras = 'bmp'
  RSLC3_ID = ''
  lt1_name = ''
  max_it1 = 5
  max_it2 = 5
  rwin = 256
  azwin = 256
  modified_2nd = 0
  check_flag = 1
  int_flag = 1
  npoly = 1
  wdir = '.'
  create_RSLC2_tab = 0
  poly_bound = 4
  nrstep = 64
  nazstep = 64
  matching_fail = 0
  ras = '.bmp'

  # verbose mode
  pg.is_verbose = True
  
  # parse arguments
  if (len(sys.argv) > 6) and re.match(r'-(\.|)\d', sys.argv[6]):  #match - and either .decimal or decimal number, no options -1, -2.... are possible
    sys.argv[6] = " " + sys.argv[6]
    
  try:
    opts, args = getopt.gnu_getopt(sys.argv[1:], "", ["poly1=", "poly2=", "cc=", "fraction=", "ph_stdev=", "it1=", "it2=", "num_ovr=", "npoly=", "nr=", "naz=", "rwin=", "azwin=", "RSLC3_tab=", "RSLC3_ID=", "lt1=", "wdir=", "no_check", "no_int", "no_cleaning", "use_existing", "ignore_errors"])
  except getopt.GetoptError as err:
    print(str(err))  # will print something like "option -a not recognized"
    usage()
  
  if len(args) < 5:
    if len(args) > 0:
      print("\nERROR: insufficient data parameters on the command line")
    usage()

  print("\nScanSAR_coreg.py arguments: %s" %str(args))
  print("ScanSAR_coreg.py options: %s\n" %str(opts))
  
  # reference
  SLC1_tab_name = args[0]
  
  exists = os.path.isfile(SLC1_tab_name)
  if not exists:
    print("\nERROR: %s not found\n" %SLC1_tab_name)
    sys.exit(-1)
  
  SLC1_tab = pg.read_tab(SLC1_tab_name)
  if SLC1_tab.ndim == 1:
    nrows = 1
    ncols = SLC1_tab.shape[0]
  else:
    nrows = SLC1_tab.shape[0]
    ncols = SLC1_tab.shape[1]
  
  if (ncols != 3):
    print("\nERROR: %s doesn't have the 3 columns format\n" %SLC1_tab_name)
    sys.exit(-1)
  
  RSLC3_tab_name = SLC1_tab_name
  
  # ID for reference files
  SLC1_ID = args[1]
  
  # second scene
  SLC2_tab_name = args[2]
  
  exists = os.path.isfile(SLC2_tab_name)
  if not exists:
    print("\nERROR: %s not found\n" %SLC2_tab_name)
    sys.exit(-1)
  
  if (SLC1_tab_name == SLC2_tab_name):
    print("\nSLC_tab files are identical for reference and second scene: %s --> exiting\n" %SLC1_tab_name)
    sys.exit(-1)
  
  SLC2_tab = pg.read_tab(SLC2_tab_name)
  
  # check number of swaths in second scene
  if SLC2_tab.ndim != SLC1_tab.ndim:
    if SLC2_tab.ndim == 1:
      nrows_2nd = 1
    else:
      nrows_2nd = SLC2_tab.shape[0]
    print("\nERROR: the number of subswaths in the second scene %d is not the same as in the reference %d" %(nrows_2nd, nrows))
    sys.exit(-1)
  
  if SLC2_tab.ndim == 1:
    ncols = SLC2_tab.shape[0]
  else:
    ncols = SLC2_tab.shape[1]
    
  if (ncols != 3):
    print("\nERROR: %s doesn't have the 3 columns format\n" %SLC2_tab_name)
    sys.exit(-1)
  
  # ID for second scene files
  SLC2_ID = args[3]

  if (SLC1_ID == SLC2_ID):
    print("\nERROR: identical ID provided for reference and second scene: %s\n" %SLC1_ID)
    sys.exit(-1)

  # coregistered second scene
  RSLC2_tab_name = args[4]
  
  if (os.path.isfile(RSLC2_tab_name)):
    if (SLC2_tab_name == RSLC2_tab_name):
      print("\nERROR: SLC_tab files are identical for second scene and resampled second scene: %s\n" %SLC2_tab_name)
      sys.exit(-1)
    
    RSLC2_tab = pg.read_tab(RSLC2_tab_name)
    
    # check number of swaths in second scene
    if RSLC2_tab.ndim != SLC1_tab.ndim:
      if RSLC2_tab.ndim == 1:
        nrows_2nd = 1
      else:
        nrows_2nd = RSLC2_tab.shape[0]
      print("\nERROR: the number of subswaths in the coregistered second scene %d is not the same as in the reference %d" %(nrows_2nd, nrows))
      sys.exit(-1)
    
    if RSLC2_tab.ndim == 1:
      ncols = RSLC2_tab.shape[0]
    else:
      ncols = RSLC2_tab.shape[1]
      
    if (ncols != 3):
      print("\nERROR: %s doesn't have the 3 columns format\n" %RSLC2_tab_name)
      sys.exit(-1)
  else:
    print("%s does not exist yet, its entries will be created with names based on SLC2_tab" %RSLC2_tab_name)
    create_RSLC2_tab = 1
    
  # height map
  if ((len(args) > 5) and (args[5] != "-")):
    hgt_name = args[5]
  
    exists = os.path.isfile(hgt_name)
    if exists:
      hgt_file_flag = 1
      hgt_val = hgt_name
    else:
      try:
        hgt_val = float(hgt_name)
      except:
        print("\nERROR: invalid entry for hgt: %s\n" %hgt_name)
        sys.exit(-1)

  if hgt_file_flag == 1:
    print("using the height file %s" %hgt_name)
  else:
    print("using a constant height value: %f m" %hgt_val)

  # range looks
  if ((len(args) > 6) and (args[6] != "-")):
    rlks = int(args[6])
  
  # azimuth looks
  if ((len(args) > 7) and (args[7] != "-")):
    azlks = int(args[7])
  
  for o, a in opts:
    # polygon 1
    if (o == "--poly1"):
      poly1_name = a
      poly1_flag = 1
    
      if not os.path.isfile(poly1_name):
        print("\nERROR: %s not found\n" %poly1_name)
        sys.exit(-1)
      
    # polygon 2
    elif (o == "--poly2"):
      poly2_name = a
      poly2_flag = 1
      
      if not os.path.isfile(poly2_name):
        print("\nERROR: %s not found\n" %poly2_name)
        sys.exit(-1)
    
    # cc
    elif (o == "--cc"):
      cc_thresh = float(a)
    
    # fraction
    elif (o == "--fraction"):
      fraction_thresh = float(a)
    
    # ph_stdev
    elif (o == "--ph_stdev"):
      stdev_thresh = float(a)
    
    # it1
    elif (o == "--it1"):
      max_it1 = int(a)
    
    # it2
    elif (o == "--it2"):
      max_it2 = int(a)
    
    # num_ovr
    elif (o == "--num_ovr"):
      max_num_ovr = int(a)
      
      if ((max_num_ovr < 5) and (max_num_ovr != 0)):
        max_num_ovr = 5
    
    # npoly
    elif (o == "--npoly"):
      npoly = int(a)
      
      if ((npoly != 1) and (npoly != 3) and (npoly != 4) and (npoly != 6)):
        print("\nERROR: invalid number of model polynomial parameters: \n" %npoly)
        sys.exit(-1)
    
    # nr
    elif (o == "--nr"):
      nrstep = int(a)
    
    # naz
    elif (o == "--naz"):
      nazstep = int(a)
    
    # rwin
    elif (o == "--rwin"):
      rwin = int(a)
    
    # azwin
    elif (o == "--azwin"):
      azwin = int(a)
    
    # co-registered ScanSAR second scene image
    elif (o == "--RSLC3_tab"):
      RSLC3_tab_name = a
      RSLC3_flag = 1
      
      if not os.path.isfile(RSLC3_tab_name):
        print("\nERROR: %s not found\n" %RSLC3_tab_name)
        sys.exit(-1)
        
      RSLC3_tab = pg.read_tab(RSLC3_tab_name)
    
      # check number of swaths in coregistered second scene
      if RSLC3_tab.ndim != SLC1_tab.ndim:
        if RSLC3_tab.ndim == 1:
          nrows_2nd = 1
        else:
          nrows_2nd = RSLC3_tab.shape[0]
        print("\nERROR: the number of subswaths in the coregistered second scene %d is not the same as in the reference %d" %(nrows_2nd, nrows))
        sys.exit(-1)
      
      if RSLC3_tab.ndim == 1:
        ncols = RSLC3_tab.shape[0]
      else:
        ncols = RSLC3_tab.shape[1]
        
      if (ncols != 3):
        print("\nERROR: %s doesn't have the 3 columns format\n" %RSLC3_tab_name)
        sys.exit(-1)
    
    # ID for co-registered second scene files
    elif (o == "--RSLC3_ID"):
      RSLC3_ID = a
      
      if (SLC2_ID == RSLC3_ID):
        print("\nERROR: identical ID provided for second scene and co-registered second scene: %s\n" %SLC2_ID)
        sys.exit(-1)
    
    # modified lookup table
    elif (o == "--lt1"):
      lt1_name = a
      
      if not os.path.isfile(lt1_name):
        print("\nERROR: %s not found\n" %lt1_name)
        sys.exit(-1)
    
    # working directory
    elif (o == "--wdir"):
      wdir = a.rstrip("/")
    
    # no_check
    elif (o == "--no_check"):
      check_flag = 0
    
    # no_int
    elif (o == "--no_int"):
      int_flag = 0
      
    # no_cleaning
    elif (o == "--no_cleaning"):
      cleaning = 0
    
    # use_existing
    elif (o == "--use_existing"):
      flag1 = 1
    
    # ignore_errors
    elif (o == "--ignore_errors"):
      error_flag = 1
    
    # option not found
    else:
      print("\nERROR: invalid option on the command line: ", o)
      sys.exit(-1)
  
  # check if working directory exists
  if not os.path.isdir(wdir):
    try:
      os.mkdir(wdir)
    except OSError:
      print("\nERROR: Creation of the directory %s failed\n" % wdir)
      sys.exit(-1)
    else:
      print("\nSuccessfully created the directory %s" % wdir)
  
  tmp_dir = wdir + '/' + tmp_dir
  
  # windows: replace \ by /
  if sys.platform == 'win32':
    for n in range(nrows):
      if (nrows == 1):
        SLC1_tab[0] = SLC1_tab[0].replace('\\', '/')
        SLC1_tab[1] = SLC1_tab[1].replace('\\', '/')
        SLC1_tab[2] = SLC1_tab[2].replace('\\', '/')
        SLC2_tab[0] = SLC2_tab[0].replace('\\', '/')
        SLC2_tab[1] = SLC2_tab[1].replace('\\', '/')
        SLC2_tab[2] = SLC2_tab[2].replace('\\', '/')
        if not create_RSLC2_tab:
          RSLC2_tab[0] = RSLC2_tab[0].replace('\\', '/')
          RSLC2_tab[1] = RSLC2_tab[1].replace('\\', '/')
          RSLC2_tab[2] = RSLC2_tab[2].replace('\\', '/')
        if RSLC3_flag:
          RSLC3_tab[0] = RSLC3_tab[0].replace('\\', '/')
          RSLC3_tab[1] = RSLC3_tab[1].replace('\\', '/')
          RSLC3_tab[2] = RSLC3_tab[2].replace('\\', '/')
      else:
        SLC1_tab[n][0] = SLC1_tab[n][0].replace('\\', '/')
        SLC1_tab[n][1] = SLC1_tab[n][1].replace('\\', '/')
        SLC1_tab[n][2] = SLC1_tab[n][2].replace('\\', '/')
        SLC2_tab[n][0] = SLC2_tab[n][0].replace('\\', '/')
        SLC2_tab[n][1] = SLC2_tab[n][1].replace('\\', '/')
        SLC2_tab[n][2] = SLC2_tab[n][2].replace('\\', '/')
        if not create_RSLC2_tab:
          RSLC2_tab[n][0] = RSLC2_tab[n][0].replace('\\', '/')
          RSLC2_tab[n][1] = RSLC2_tab[n][1].replace('\\', '/')
          RSLC2_tab[n][2] = RSLC2_tab[n][2].replace('\\', '/')
        if RSLC3_flag:
          RSLC3_tab[n][0] = RSLC3_tab[n][0].replace('\\', '/')
          RSLC3_tab[n][1] = RSLC3_tab[n][1].replace('\\', '/')
          RSLC3_tab[n][2] = RSLC3_tab[n][2].replace('\\', '/')
  
  # check if files in tab files exist
  if (nrows == 1):
    if not os.path.isfile(SLC1_tab[0]):
      print("\nERROR: %s not found\n" %SLC1_tab[0])
      sys.exit(-1)
      
    if not os.path.isfile(SLC1_tab[1]):
      print("\nERROR: %s not found\n" %SLC1_tab[1])
      sys.exit(-1)
      
    if not os.path.isfile(SLC1_tab[2]):
      print("\nERROR: %s not found\n" %SLC1_tab[2])
      sys.exit(-1)
    
    if not os.path.isfile(SLC2_tab[0]):
      print("\nERROR: %s not found\n" %SLC2_tab[0])
      sys.exit(-1)
      
    if not os.path.isfile(SLC2_tab[1]):
      print("\nERROR: %s not found\n" %SLC2_tab[1])
      sys.exit(-1)
      
    if not os.path.isfile(SLC2_tab[2]):
      print("\nERROR: %s not found\n" %SLC2_tab[2])
      sys.exit(-1)
      
    if RSLC3_flag:
      if not os.path.isfile(RSLC3_tab[0]):
        print("\nERROR: %s not found\n" %RSLC3_tab[0])
        sys.exit(-1)
        
      if not os.path.isfile(RSLC3_tab[1]):
        print("\nERROR: %s not found\n" %RSLC3_tab[1])
        sys.exit(-1)
        
      if not os.path.isfile(RSLC3_tab[2]):
        print("\nERROR: %s not found\n" %RSLC3_tab[2])
        sys.exit(-1)
  
  else:
    for n in range(nrows):
      if not os.path.isfile(SLC1_tab[n][0]):
        print("\nERROR: %s not found\n" %SLC1_tab[n][0])
        sys.exit(-1)
        
      if not os.path.isfile(SLC1_tab[n][1]):
        print("\nERROR: %s not found\n" %SLC1_tab[n][1])
        sys.exit(-1)
        
      if not os.path.isfile(SLC1_tab[n][2]):
        print("\nERROR: %s not found\n" %SLC1_tab[n][2])
        sys.exit(-1)
      
      if not os.path.isfile(SLC2_tab[n][0]):
        print("\nERROR: %s not found\n" %SLC2_tab[n][0])
        sys.exit(-1)
        
      if not os.path.isfile(SLC2_tab[n][1]):
        print("\nERROR: %s not found\n" %SLC2_tab[n][1])
        sys.exit(-1)
        
      if not os.path.isfile(SLC2_tab[n][2]):
        print("\nERROR: %s not found\n" %SLC2_tab[n][2])
        sys.exit(-1)
        
      if RSLC3_flag:
        if not os.path.isfile(RSLC3_tab[n][0]):
          print("\nERROR: %s not found\n" %RSLC3_tab[n][0])
          sys.exit(-1)
          
        if not os.path.isfile(RSLC3_tab[n][1]):
          print("\nERROR: %s not found\n" %RSLC3_tab[n][1])
          sys.exit(-1)
          
        if not os.path.isfile(RSLC3_tab[n][2]):
          print("\nERROR: %s not found\n" %RSLC3_tab[n][2])
          sys.exit(-1)
  
  # automatically create RSLC2_tab
  if create_RSLC2_tab:
    RSLC2_tab = []
    
    for n in range(nrows):
      if nrows == 1:
        if '.slc' in SLC2_tab[0]:
          RSLC2_name = SLC2_tab[0].replace('.slc', '.rslc')
        else:
          RSLC2_name = SLC2_tab[0] + '.rslc'
        
        if '.slc' in SLC2_tab[1]:
          RSLC2_par_name = SLC2_tab[1].replace('.slc', '.rslc')
        else:
          RSLC2_par_name = SLC2_tab[0] + '.rslc.par'
          
        if '.slc' in SLC2_tab[2]:
          RSLC2_tops_par_name = SLC2_tab[2].replace('.slc', '.rslc')
        else:
          RSLC2_tops_par_name = SLC2_tab[0] + '.rslc.tops_par'
        
        RSLC2_tab = [RSLC2_name, RSLC2_par_name, RSLC2_tops_par_name]
      
      else:
        if '.slc' in SLC2_tab[n][0]:
          RSLC2_name = SLC2_tab[n][0].replace('.slc', '.rslc')
        else:
          RSLC2_name = SLC2_tab[n][0] + '.rslc'
        
        if '.slc' in SLC2_tab[n][1]:
          RSLC2_par_name = SLC2_tab[n][1].replace('.slc', '.rslc')
        else:
          RSLC2_par_name = SLC2_tab[n][0] + '.rslc.par'
          
        if '.slc' in SLC2_tab[n][2]:
          RSLC2_tops_par_name = SLC2_tab[n][2].replace('.slc', '.rslc')
        else:
          RSLC2_tops_par_name = SLC2_tab[n][0] + '.rslc.tops_par'
          
        RSLC2_tab.append([RSLC2_name, RSLC2_par_name, RSLC2_tops_par_name])
    
    if ((ntpath.dirname(RSLC2_tab_name) != '') and not os.path.isdir(ntpath.dirname(RSLC2_tab_name))):
      try:
        os.makedirs(ntpath.dirname(RSLC2_tab_name))
      except OSError:
        print("\nERROR: Creation of the directory %s failed\n" %(ntpath.dirname(RSLC2_tab_name)))
        sys.exit(-1)
      else:
        print("\nSuccessfully created the directory %s" %(ntpath.dirname(RSLC2_tab_name)))
      
    pg.write_tab(RSLC2_tab, RSLC2_tab_name)
  
  # check that folders exist
  else:
    if (nrows == 1):
      if ((ntpath.dirname(RSLC2_tab[0]) != '') and not os.path.isdir(ntpath.dirname(RSLC2_tab[0]))):
        print("\nERROR: directory %s in %s not found\n" %(ntpath.dirname(RSLC2_tab[0]), RSLC2_tab_name))
        sys.exit(-1)
      
      if ((ntpath.dirname(RSLC2_tab[1]) != '') and not os.path.isdir(ntpath.dirname(RSLC2_tab[1]))):
        print("\nERROR: directory %s in %s not found\n" %(ntpath.dirname(RSLC2_tab[1]), RSLC2_tab_name))
        sys.exit(-1)
      
      if ((ntpath.dirname(RSLC2_tab[2]) != '') and not os.path.isdir(ntpath.dirname(RSLC2_tab[2]))):
        print("\nERROR: directory %s in %s not found\n" %(ntpath.dirname(RSLC2_tab[2]), RSLC2_tab_name))
        sys.exit(-1)
    else:
      for n in range(nrows):
        if ((ntpath.dirname(RSLC2_tab[n][0]) != '') and not os.path.isdir(ntpath.dirname(RSLC2_tab[n][0]))):
          print("\nERROR: directory %s in %s not found\n" %(ntpath.dirname(RSLC2_tab[n][0]), RSLC2_tab_name))
          sys.exit(-1)
        
        if ((ntpath.dirname(RSLC2_tab[n][1]) != '') and not os.path.isdir(ntpath.dirname(RSLC2_tab[n][1]))):
          print("\nERROR: directory %s in %s not found\n" %(ntpath.dirname(RSLC2_tab[n][1]), RSLC2_tab_name))
          sys.exit(-1)
        
        if ((ntpath.dirname(RSLC2_tab[n][2]) != '') and not os.path.isdir(ntpath.dirname(RSLC2_tab[n][2]))):
          print("\nERROR: directory %s in %s not found\n" %(ntpath.dirname(RSLC2_tab[n][2]), RSLC2_tab_name))
          sys.exit(-1)  
  
  # set the raster file type extension determined from environment variable, valid values: bmp, ras, tif
  ras_list = []
  status = pg.get_GAMMA_RASTER(0, cout = ras_list, stdout_flag = False)
  if (status == 0):
    ras = ras_list[0]
  print("raster image file extension from get_GAMMA_RASTER: %s" %ras)
  
  # check if LAT programs are available
  try:
    pg.poly_mask
  except:
    poly_mask_flag = 0
    print("LAT program poly_mask is not available")
  else:
    print("LAT program poly_mask is available")
  
  # set output file names
  pair_name = SLC1_ID + '_' + SLC2_ID
  
  SLC2_tab_out_name = tmp_dir + '/' + ntpath.basename(SLC2_tab_name) + '_mod'
  diff_par_name = tmp_dir + '/' + pair_name + '.diff_par'
  off_par_name = wdir + '/' + pair_name + '.off'
  off_par_start_name = tmp_dir + '/' + pair_name + '.off.start'
  doff_par_name = tmp_dir + '/' + pair_name + '.doff'
  offs_name = tmp_dir + '/' + pair_name + '.offs'
  snr_name = tmp_dir + '/' + pair_name + '.snr'
  log1_name = tmp_dir + '/SLC_interp_lt_ScanSAR.1.out'
  log2_name = tmp_dir + '/SLC_interp_lt_ScanSAR.2.out'
  log3_name = tmp_dir + '/SLC_interp_lt_ScanSAR.3.out'
  fit_name = []
  az_ovr_log = []
  
  SLC_name = wdir + '/' + SLC2_ID + '.slc'
  SLC_par_name = SLC_name + '.par'
  MLI_name = wdir + '/' + SLC2_ID + '.mli'
  MLI_par_name = MLI_name + '.par'
  RSLC_name = wdir + '/' + SLC2_ID + '.rslc'
  RSLC_par_name = RSLC_name + '.par'
  REF_SLC_name = wdir + '/' + SLC1_ID + '.rslc'
  REF_SLC_par_name = REF_SLC_name + '.par'
  REF_MLI_name = wdir + '/' + SLC1_ID + '.rmli'
  REF_MLI_par_name = REF_MLI_name + '.par'
  if (RSLC3_flag and RSLC3_ID != ''):
    RSLC3_name = wdir + '/' + RSLC3_ID + '.rslc'
    RSLC3_par_name = RSLC3_name + '.par'
    RMLI3_name = wdir + '/' + RSLC3_ID + '.rmli'
    RMLI3_par_name = RMLI3_name + '.par'
  
  REF_MLI_ras_name = REF_MLI_name + '.' + ras
  MLI_ras_name = MLI_name + '.' + ras
  MLI_lt_name = MLI_name + '.lt'
  MLI_lt_masked_name = MLI_lt_name + '.masked'
  MLI_lt_az_ovr_name = tmp_dir + '/' + SLC2_ID + '.mli.lt.az_ovr'
  MLI_lt_az_ovr_tmp_name = tmp_dir + '/' + SLC2_ID + '.mli.lt.az_ovr.tmp'
  matching_poly_name = tmp_dir + '/' + SLC1_ID + '.MLI_matching.poly'
  az_ovr_root_name = tmp_dir + '/' + SLC1_ID
  az_ovr_poly_name = tmp_dir + '/' + SLC1_ID + '.MLI_az_ovr.poly'
  sim_unw_name = wdir + '/' + pair_name + '.sim_unw'
  diff_name = wdir + '/' + pair_name + '.diff'
  diff_ras_name = diff_name + '.' + ras
  results_name = wdir + '/' + pair_name + '.results'
  if (RSLC3_flag and RSLC3_ID != ''):
    sim_unw3_name = wdir + '/' + RSLC3_ID + '_' + SLC2_ID + '.sim_unw'
    diff3_name = wdir + '/' + RSLC3_ID + '_' + SLC2_ID + '.diff'
    diff3_ras_name = diff3_name + '.' + ras
  
  # check if output mosaicked files have same name as input burst files
  if (nrows == 1):
    if os.path.normpath(os.path.realpath(REF_SLC_name)) == os.path.normpath(os.path.realpath(SLC1_tab[0])):
      print("\nERROR: same filename used for input SLC file and output mosaicked SLC file (%s), please define a different SLC1_ID name\n" %REF_SLC_name)
      sys.exit(-1)
      
    if os.path.normpath(os.path.realpath(REF_SLC_par_name)) == os.path.normpath(os.path.realpath(SLC1_tab[1])):
      print("\nERROR: same filename used for input SLC parameter file and output mosaicked SLC parameter file (%s), please define a different SLC1_ID name\n" %REF_SLC_par_name)
      sys.exit(-1)
    
    if os.path.normpath(os.path.realpath(SLC_name)) == os.path.normpath(os.path.realpath(SLC2_tab[0])):
      print("\nERROR: same filename used for input SLC file and output mosaicked SLC file (%s), please define a different SLC2_ID name\n" %SLC_name)
      sys.exit(-1)
    
    if os.path.normpath(os.path.realpath(SLC_par_name)) == os.path.normpath(os.path.realpath(SLC2_tab[1])):
      print("\nERROR: same filename used for input SLC parameter file and output mosaicked SLC parameter file (%s), please define a different SLC2_ID name\n" %SLC_par_name)
      sys.exit(-1)
    
    if os.path.normpath(os.path.realpath(RSLC_name)) == os.path.normpath(os.path.realpath(RSLC2_tab[0])):
      print("\nERROR: same filename used for output RSLC file and output mosaicked RSLC file (%s), please define a different SLC2_ID name\n" %RSLC_name)
      sys.exit(-1)
    
    if os.path.normpath(os.path.realpath(RSLC_par_name)) == os.path.normpath(os.path.realpath(RSLC2_tab[1])):
      print("\nERROR: same filename used for output RSLC parameter file and output mosaicked RSLC parameter file (%s), please define a different SLC2_ID name\n" %RSLC_par_name)
      sys.exit(-1)
    
    if (RSLC3_flag and RSLC3_ID != ''):
      if os.path.normpath(os.path.realpath(RSLC3_name)) == os.path.normpath(os.path.realpath(RSLC3_tab[0])):
        print("\nERROR: same filename used for input SLC file and output mosaicked SLC file (%s), please define a different RSLC3_ID name\n" %RSLC3_name)
        sys.exit(-1)
      
      if os.path.normpath(os.path.realpath(RSLC3_par_name)) == os.path.normpath(os.path.realpath(RSLC3_tab[1])):
        print("\nERROR: same filename used for input SLC parameter file and output mosaicked SLC parameter file (%s), please define a different RSLC3_ID name\n" %RSLC3_par_name)
        sys.exit(-1)  

  else:
    for n in range(nrows):
      if os.path.normpath(os.path.realpath(REF_SLC_name)) == os.path.normpath(os.path.realpath(SLC1_tab[n][0])):
        print("\nERROR: same filename used for input SLC file and output mosaicked SLC file (%s), please define a different SLC1_ID name\n" %REF_SLC_name)
        sys.exit(-1)
      
      if os.path.normpath(os.path.realpath(REF_SLC_par_name)) == os.path.normpath(os.path.realpath(SLC1_tab[n][1])):
        print("\nERROR: same filename used for input SLC parameter file and output mosaicked SLC parameter file (%s), please define a different SLC1_ID name\n" %REF_SLC_par_name)
        sys.exit(-1)
      
      if os.path.normpath(os.path.realpath(SLC_name)) == os.path.normpath(os.path.realpath(SLC2_tab[n][0])):
        print("\nERROR: same filename used for input SLC file and output mosaicked SLC file (%s), please define a different SLC2_ID name\n" %SLC_name)
        sys.exit(-1)
        
      if os.path.normpath(os.path.realpath(SLC_par_name)) == os.path.normpath(os.path.realpath(SLC2_tab[n][1])):
        print("\nERROR: same filename used for input SLC parameter file and output mosaicked SLC parameter file (%s), please define a different SLC2_ID name\n" %SLC_par_name)
        sys.exit(-1)
      
      if os.path.normpath(os.path.realpath(RSLC_name)) == os.path.normpath(os.path.realpath(RSLC2_tab[n][0])):
        print("\nERROR: same filename used for output RSLC file and output mosaicked RSLC file (%s), please define a different SLC2_ID name\n" %RSLC_name)
        sys.exit(-1)
      
      if os.path.normpath(os.path.realpath(RSLC_par_name)) == os.path.normpath(os.path.realpath(RSLC2_tab[n][1])):
        print("\nERROR: same filename used for output RSLC parameter file and output mosaicked RSLC parameter file (%s), please define a different SLC2_ID name\n" %RSLC_par_name)
        sys.exit(-1)
        
      if (RSLC3_flag and RSLC3_ID != ''):
        if os.path.normpath(os.path.realpath(RSLC3_name)) == os.path.normpath(os.path.realpath(RSLC3_tab[n][0])):
          print("\nERROR: same filename used for input SLC file and output mosaicked SLC file (%s), please define a different RSLC3_ID name\n" %RSLC3_name)
          sys.exit(-1)
          
        if os.path.normpath(os.path.realpath(RSLC3_par_name)) == os.path.normpath(os.path.realpath(RSLC3_tab[n][1])):
          print("\nERROR: same filename used for input SLC parameter file and output mosaicked SLC parameter file (%s), please define a different RSLC3_ID name\n" %RSLC3_par_name)
          sys.exit(-1)
  
  # create temporary directory
  if not os.path.isdir(tmp_dir):
    try:
      os.mkdir(tmp_dir)
    except OSError:
      print("\nERROR: Creation of the directory %s failed\n" % tmp_dir)
      sys.exit(-1)
    else:
      print("\nSuccessfully created the directory %s" % tmp_dir)
  
  if os.path.isfile(log1_name):
    os.remove(log1_name)
  if os.path.isfile(log2_name):
    os.remove(log2_name)
  if os.path.isfile(log3_name):
    os.remove(log3_name)
      
  print('')
  
  # check if the input reference and second scene include for each sub-swath the corresponding bursts
  
  # automatically generate SLC_tab_out
  SLC2_tab_out = []
  
  for i in range(nrows):
    # SLC file
    if (nrows == 1):
      SLC2_name = ntpath.basename(str(SLC2_tab[0]))
    else:
      SLC2_name = ntpath.basename(str(SLC2_tab[i][0]))
    
    dot_pos = SLC2_name.find('.')
    if dot_pos != -1:
      SLC2_out_name = tmp_dir + '/' + ntpath.basename(SLC2_name[:dot_pos] + '_mod' + SLC2_name[dot_pos:])
    else:
      SLC2_out_name = tmp_dir + '/' + ntpath.basename(SLC2_name + '_mod')
    
    # SLC parameter file
    if (nrows == 1):
      SLC2_par_name = str(SLC2_tab[1])
    else:
      SLC2_par_name = str(SLC2_tab[i][1])
    
    dot_pos = SLC2_par_name.find('.')
    if dot_pos != -1:
      SLC2_par_out_name = tmp_dir + '/' + ntpath.basename(SLC2_par_name[:dot_pos] + '_mod' + SLC2_par_name[dot_pos:])
    else:
      SLC2_par_out_name = tmp_dir + '/' + ntpath.basename(SLC2_par_name + '_mod')
    
    # TOPS parameter file
    if (nrows == 1):
      SLC2_tops_par_name = str(SLC2_tab[2])
    else:
      SLC2_tops_par_name = str(SLC2_tab[i][2])
      
    dot_pos = SLC2_tops_par_name.find('.')
    if dot_pos != -1:
      SLC2_tops_par_out_name = tmp_dir + '/' + ntpath.basename(SLC2_tops_par_name[:dot_pos] + '_mod' + SLC2_tops_par_name[dot_pos:])
    else:
      SLC2_tops_par_out_name = tmp_dir + '/' + ntpath.basename(SLC2_tops_par_name + '_mod')
    
    if nrows == 1:
      SLC2_tab_out = [SLC2_out_name, SLC2_par_out_name, SLC2_tops_par_out_name]
    else:
      SLC2_tab_out.append([SLC2_out_name, SLC2_par_out_name, SLC2_tops_par_out_name])
    
    pg.write_tab(SLC2_tab_out, SLC2_tab_out_name)
  
  if check_flag:
    status = pg.ScanSAR_coreg_check(SLC1_tab_name, SLC2_tab_name, SLC2_tab_out_name, wdir, cleaning)
    check_output(status, error_flag, cleaning, tmp_dir)
  else:
    shutil.copyfile(SLC2_tab_name, SLC2_tab_out_name)
  
  # check if SLC2_tab_out_name same as SLC1_tab_name
  SLC2_tab_out = pg.read_tab(SLC2_tab_out_name)
  for i in range(nrows):
    for j in range(ncols):
      if (nrows == 1):
        if SLC2_tab[j] != SLC2_tab_out[j]:
          modified_2nd = 1
      else:
        if SLC2_tab[i][j] != SLC2_tab_out[i][j]:
          modified_2nd = 1
  
  if modified_2nd:
    SLC2_tab_name = SLC2_tab_out_name
    SLC2_tab = pg.read_tab(SLC2_tab_name)

  # check if more than one burst in any subswath
  if max_it2 > 0:
    max_nburst = 0
    for i in range(nrows):
      if (nrows == 1):
        TOPS_par = pg.ParFile(SLC1_tab[2])
      else:
        TOPS_par = pg.ParFile(SLC1_tab[i][2])
      nburst = TOPS_par.get_value('number_of_bursts', dtype = int, index = 0)
      if nburst > max_nburst:
        max_nburst = nburst
    if max_nburst <= 1:
      max_it2 = 0
      print("No subswath has more than one burst, spectral diversity refinement will not be performed\n")
  
  # initialize the output coregistration quality file
  quality_name = wdir + '/' + pair_name + '.coreg_quality'
  quality = open(quality_name, "w+")
  quality.write("ScanSAR coregistration quality file\n")
  quality.write("###################################\n")
  quality.write("%s\n\n" %(str(t_cur)))
  
  # write out command used and script versions
  quality.write("command used:\n")
  quality.write("ScanSAR_coreg.py")
  for i in range(1, len(sys.argv)):
    quality.write(" %s" %sys.argv[i])
  quality.write("\n\n")
  quality.write("reference:    %s %s %s %s\n" %(SLC1_ID, REF_SLC_name, REF_SLC_par_name, SLC1_tab_name))
  quality.write("second scene: %s %s %s %s\n" %(SLC2_ID, SLC_name, SLC_par_name, SLC2_tab_name))
  quality.write("coregistered second scene: %s %s %s %s\n" %(SLC2_ID, RSLC_name, RSLC_par_name, RSLC2_tab_name))
  quality.write("reference for spectral diversity refinement: %s\n" %(RSLC3_tab_name))
  quality.write("polygon used for matching (poly1):           %s\n" %(poly1_name))
  quality.write("polygon used for spectral diversity (poly2): %s\n" %(poly2_name))
  quality.close()

  # generate SLC and MLI mosaics for reference burst SLC
  if (flag1 and os.path.isfile(REF_SLC_name) and os.path.isfile(REF_SLC_par_name)):
    print("using existing SLC mosaic of reference: %s %s" %(REF_SLC_name, REF_SLC_par_name))
  else:
    status = pg.SLC_mosaic_ScanSAR(SLC1_tab_name, REF_SLC_name, REF_SLC_par_name, rlks, azlks, 1)
    check_output(status, error_flag, cleaning, tmp_dir)
  
  if (flag1 and os.path.isfile(REF_MLI_name) and os.path.isfile(REF_MLI_par_name)):
    print("using existing MLI mosaic of reference: %s %s" %(REF_MLI_name, REF_MLI_par_name))
  else:
    status = pg.multi_look(REF_SLC_name, REF_SLC_par_name, REF_MLI_name, REF_MLI_par_name, rlks, azlks)
    check_output(status, error_flag, cleaning, tmp_dir)

  REF_MLI_par = pg.ParFile(REF_MLI_par_name)
  REF_SLC_par = pg.ParFile(REF_SLC_par_name)
  REF_MLI_width = REF_MLI_par.get_value('range_samples', dtype = int, index = 0)
  REF_SLC_width = REF_SLC_par.get_value('range_samples', dtype = int, index = 0)
  REF_SLC_nlines = REF_SLC_par.get_value('azimuth_lines', dtype = int, index = 0)
  
  if (flag1 and os.path.isfile(REF_MLI_ras_name)):
    print("using existing rasterfile of MLI mosaic of reference: %s" %(REF_MLI_ras_name))
  else:
    status = pg.raspwr(REF_MLI_name, REF_MLI_width, '-', '-', '-', '-', '-', '-', '-', REF_MLI_ras_name)
    check_output(status, error_flag, cleaning, tmp_dir)

  # generate SLC and MLI mosaics for second scene burst SLC
  if (flag1 and os.path.isfile(SLC_name) and os.path.isfile(SLC_par_name)):
    print("using existing SLC mosaic of second scene: %s %s" %(SLC_name, SLC_par_name))
  else:
    status = pg.SLC_mosaic_ScanSAR(SLC2_tab_name, SLC_name, SLC_par_name, rlks, azlks, 1)
    check_output(status, error_flag, cleaning, tmp_dir)
  
  if (flag1 and os.path.isfile(MLI_name) and os.path.isfile(MLI_par_name)):
    print("using existing MLI mosaic of second scene: %s %s" %(MLI_name, MLI_par_name))
  else:
    status = pg.multi_look(SLC_name, SLC_par_name, MLI_name, MLI_par_name, rlks, azlks)
    check_output(status, error_flag, cleaning, tmp_dir)

  MLI_par = pg.ParFile(MLI_par_name)
  MLI_width = MLI_par.get_value('range_samples', dtype = int, index = 0)
  
  if (flag1 and os.path.isfile(MLI_ras_name)):
    print("using existing rasterfile of MLI mosaic of second scene: %s" %(MLI_ras_name))
  else:
    status = pg.raspwr(MLI_name, MLI_width, '-', '-', '-', '-', '-', '-', '-', MLI_ras_name)
    check_output(status, error_flag, cleaning, tmp_dir)
  
  # determine lookup table based on orbit data and DEM
  if (flag1 and os.path.isfile(MLI_lt_name)):
    print("using existing lookup table: %s" %(MLI_lt_name))
  elif (lt1_name != ''):
    print("using lookup table provided on the command line: %s" %(lt1_name))
    max_it1 = 0
    try:
      shutil.copyfile(lt1_name, MLI_lt_name)
    except shutil.SameFileError:
      pass
  else:
    status = pg.rdc_trans(REF_MLI_par_name, hgt_val, MLI_par_name, MLI_lt_name)
    check_output(status, error_flag, cleaning, tmp_dir)

  # Iterative improvement of refinement offsets between reference SLC and
  # resampled second scene RSLC using intensity matching (offset_pwr_tracking)
  # Remarks: here only a section of the data is used if a polygon is indicated
  # the lookup table is iteratively refined with the estimated offsets 
  # only a constant offset in range and azimuth (along all burst and swaths) is considered 
  
  if os.path.isfile(off_par_name):
    os.remove(off_par_name)

  status = pg.create_offset(REF_SLC_par_name, SLC_par_name, off_par_name, 1, rlks, azlks, 0)
  check_output(status, error_flag, cleaning, tmp_dir)
  
  if (max_it1 > 0):

    # determine starting and ending rows and cols in polygon file
    # used to speed up the offset estimation
    
    print("")
          
    r1 = 0
    r2 = REF_SLC_width-1
    az1 = 0
    az2 = REF_SLC_nlines-1
    
    if (poly1_flag):
      
      poly1_list = []
      poly1_rows = 0
      poly1 = open(poly1_name, "r")
      for line in poly1:
        if (line.strip() != ''):
          poly1_list.append((line.strip()).split())
          poly1_rows += 1
      
      r1 = int(poly1_list[0][0])
      r2 = int(poly1_list[0][0])
      az1 = int(poly1_list[0][1])
      az2 = int(poly1_list[0][1])
    
      for n in range(1, poly1_rows):
        if (int(poly1_list[n][0]) < r1):
          r1 = int(poly1_list[n][0])
        if (int(poly1_list[n][0]) > r2):
          r2 = int(poly1_list[n][0])
        if (int(poly1_list[n][1]) < az1):
          az1 = int(poly1_list[n][1])
        if (int(poly1_list[n][1]) > az2):
          az2 = int(poly1_list[n][1])
          
      print("MLI region of interest from polygon: r1: %d   r2: %d   az1: %d   az2 = %d" %(r1, r2, az1, az2))
      
      if ((r1 == r2) or (az1 == az2)):
        r1 = 0
        r2 = REF_SLC_width-1
        az1 = 0
        az2 = REF_SLC_nlines-1
      else:
        r1 = r1*rlks
        r2 = r2*rlks
        az1 = az1*azlks
        az2 = az2*azlks
        
      print("SLC region of interest from polygon: r1: %d   r2: %d   az1: %d   az2 = %d" %(r1, r2, az1, az2))
    
    print("SLC region of interest: r1: %d   r2: %d   az1: %d   az2 = %d" %(r1, r2, az1, az2))
    
    r1 = r1 + int(np.ceil(rwin/2)) + rlks * poly_bound
    r2 = r2 - rlks * poly_bound 
    rstep = int(np.floor((r2 - r1 + 1 - rwin/2)/(nrstep - 1)))
    r2 = r1 + nrstep * rstep - 1
    
    az1 = az1 + int(np.ceil(azwin/2)) + azlks * poly_bound
    az2 = az2 - azlks * poly_bound 
    azstep = int(np.floor((az2 - az1 + 1 - azwin/2)/(nazstep - 1)))
    az2 = az1 + nazstep * azstep - 1
    
    print("rstep, azstep: %d %d\n" %(rstep, azstep))
    print("adapted SLC region of interest: r1: %d   r2: %d   az1: %d   az2 = %d" %(r1, r2, az1, az2))
      
    # mask for polygon region poly1 that is at the same time used for intensity matching
    if (flag1 and os.path.isfile(MLI_lt_masked_name)):
      print("using existing masked lookup table: %s" %(MLI_lt_masked_name))
      
    else:
      if (poly_mask_flag):
        status = pg.offset_pwr_tracking_polygons(REF_SLC_par_name, off_par_name, rlks, azlks, rwin, azwin, matching_poly_name, rstep, azstep, r1, r2, az1, az2, poly_bound, poly_bound)
        check_output(status, error_flag, cleaning, tmp_dir)
        
        if poly1_flag:
          MLI_lt_masked_tmp_name = "%s/%s.mli.lt.masked.tmp.0" %(tmp_dir, SLC2_ID)
          
          status = pg.poly_mask(MLI_lt_name, MLI_lt_masked_tmp_name, REF_MLI_width, matching_poly_name, 0, 1)
          check_output(status, error_flag, cleaning, tmp_dir)
          status = pg.poly_mask(MLI_lt_masked_tmp_name, MLI_lt_masked_name, REF_MLI_width, poly1_name, 0, 1)
          check_output(status, error_flag, cleaning, tmp_dir)
        
        else:
          status = pg.poly_mask(MLI_lt_name, MLI_lt_masked_name, REF_MLI_width, matching_poly_name, 0, 1)
          check_output(status, error_flag, cleaning, tmp_dir)
    
      else:
        shutil.copyfile(MLI_lt_name, MLI_lt_masked_name)
   
    quality = open(quality_name, "a+")
    quality.write("\nIterative improvement of refinement offset using intensity matching:\n")
    quality.close()
    
    # iterate while azimuth correction > 0.01 SLC pixel or maximum number of iterations has been reached
    it = 0
    dr = 1
    daz = 1
    daz_value_icc = 0.0 # ML 2023/10: will estimate azi in icc and then use it in log for daz from SD
    while (((abs(daz) > 0.01) or (abs(dr) > 0.01)) and (it < max_it1)):
      # increase iteration counter
      it = it + 1
      print("offset refinement using intensity matching iteration %d" %it)
  
      shutil.copyfile(off_par_name, off_par_start_name)
      
      status = pg.SLC_interp_lt_ScanSAR(SLC2_tab_name, SLC_par_name, SLC1_tab_name, REF_SLC_par_name, MLI_lt_masked_name, REF_MLI_par_name, MLI_par_name, off_par_start_name, RSLC2_tab_name, RSLC_name, RSLC_par_name, logf = log1_name, stdout_flag = False)
      check_output(status, error_flag, cleaning, tmp_dir)
        
      if os.path.isfile(doff_par_name):
        os.remove(doff_par_name)
    
      status = pg.create_offset(REF_SLC_par_name, SLC_par_name, doff_par_name, 1, rlks, azlks, 0)
      check_output(status, error_flag, cleaning, tmp_dir)
      
      # no oversampling as this is not done well because of the doppler ramp
      status = pg.offset_pwr_tracking(REF_SLC_name, RSLC_name, REF_SLC_par_name, RSLC_par_name, doff_par_name, offs_name, snr_name, rwin, azwin, '-', 1, 0.2, rstep, azstep, r1, r2, az1, az2)
      
      if status == 0:
        fit_name.append("%s/%s.off.%d.out" %(tmp_dir, pair_name, it))
        if os.path.isfile(fit_name[it-1]):
          os.remove(fit_name[it-1])
        fit_list = []
        status = pg.offset_fit(offs_name, snr_name, doff_par_name, '-', '-', 0.2, npoly, 0, logf = fit_name[it-1], cout = fit_list)
        
        if status == 0:
          for item in fit_list:
            if "final model fit std. dev. (samples) range:" in item:
              line = item.split()
              range_stdev = float(line[7])
              azimuth_stdev = float(line[9])
        else:
          matching_fail = 1
          range_stdev = 0.0
          azimuth_stdev = 0.0
          
          if os.path.isfile(doff_par_name):
            os.remove(doff_par_name)
        
          status = pg.create_offset(REF_SLC_par_name, SLC_par_name, doff_par_name, 1, rlks, azlks, 0)
          check_output(status, error_flag, cleaning, tmp_dir)
      
      else:
        matching_fail = 1
        range_stdev = 0.0
        azimuth_stdev = 0.0
        
        if os.path.isfile(doff_par_name):
          os.remove(doff_par_name)
      
        status = pg.create_offset(REF_SLC_par_name, SLC_par_name, doff_par_name, 1, rlks, azlks, 0)
        check_output(status, error_flag, cleaning, tmp_dir)
      
      # lookup table refinement
      # determine range and azimuth corrections for lookup table (in mli pixels)
      doff_par = pg.ParFile(doff_par_name)
      dr_list = doff_par.get_value('range_offset_polynomial', dtype = float)
      daz_list = doff_par.get_value('azimuth_offset_polynomial', dtype = float)
      dr = dr_list[0]
      daz = daz_list[0]
      if it == 1:
        daz_value_icc = daz # ML, see above ### but need to add daz_value_icc only from the first iteration

      dr_list_mli = [0] * 6
      dr_list_mli[0] = dr_list[0]/rlks
      dr_list_mli[1] = dr_list[1]*rlks/rlks
      dr_list_mli[2] = dr_list[2]*azlks/rlks
      dr_list_mli[3] = dr_list[3]*(rlks*azlks)/rlks
      dr_list_mli[4] = dr_list[4]*rlks**2/rlks
      dr_list_mli[5] = dr_list[5]*azlks**2/rlks
      
      daz_list_mli = [0] * 6
      daz_list_mli[0] = 0 #daz_list[0]/azlks  # ML 2023/10: setting icc_based azoff to 0 (mitigate effect of ionosphere in ICC that would influence daz_SD
      daz_list_mli[1] = daz_list[1]*rlks/azlks
      daz_list_mli[2] = daz_list[2]*azlks/azlks
      daz_list_mli[3] = daz_list[3]*(rlks*azlks)/azlks
      daz_list_mli[4] = daz_list[4]*rlks**2/azlks
      daz_list_mli[5] = daz_list[5]*azlks**2/azlks
      
      print("dr_mli = %f + %e*r + %e*az + %e*r*az + %e*r*r + %e*az*az" %(dr_list_mli[0], dr_list_mli[1], dr_list_mli[2], dr_list_mli[3], dr_list_mli[4], dr_list_mli[5]))
      print("daz_mli = %f + %e*r + %e*az + %e*r*az + %e*r*r + %e*az*az\n" %(daz_list_mli[0], daz_list_mli[1], daz_list_mli[2], daz_list_mli[3], daz_list_mli[4], daz_list_mli[5]))
      
      refinement_file = open("%s/%s.refinement.iteration.%d" %(tmp_dir, pair_name, it), "w+")
      refinement_file.write("dr_mli = %f + %e*r + %e*az + %e*r*az + %e*r*r + %e*az*az\n" %(dr_list_mli[0], dr_list_mli[1], dr_list_mli[2], dr_list_mli[3], dr_list_mli[4], dr_list_mli[5]))
      refinement_file.write("daz_mli = %f + %e*r + %e*az + %e*r*az + %e*r*r + %e*az*az\n" %(daz_list_mli[0], daz_list_mli[1], daz_list_mli[2], daz_list_mli[3], daz_list_mli[4], daz_list_mli[5]))
      refinement_file.close()
      
      if os.path.isfile(diff_par_name):
        os.remove(diff_par_name)
  
      status = pg.create_diff_par(REF_MLI_par_name, REF_MLI_par_name, diff_par_name, 1, 0)
      check_output(status, error_flag, cleaning, tmp_dir)
      
      diff_par = pg.ParFile(diff_par_name)
      diff_par.set_value('range_offset_polynomial', dr_list_mli)
      diff_par.set_value('azimuth_offset_polynomial', daz_list_mli)
      diff_par.write_par(diff_par_name)
      
      shutil.copyfile(diff_par_name, "%s.%d" %(diff_par_name, it))

      # if poly1 exists then update unmasked and masked lookup table
      MLI_lt_tmp_name = "%s/%s.mli.lt.tmp.%d" %(tmp_dir, SLC2_ID, it)
      MLI_lt_masked_tmp_name = "%s/%s.mli.lt.masked.tmp.%d" %(tmp_dir, SLC2_ID, it)
      
      if (poly_mask_flag):
        shutil.copyfile(MLI_lt_name, MLI_lt_tmp_name)
        shutil.copyfile(MLI_lt_masked_name, MLI_lt_masked_tmp_name)
        status = pg.gc_map_fine(MLI_lt_tmp_name, REF_MLI_width, diff_par_name, MLI_lt_name)
        check_output(status, error_flag, cleaning, tmp_dir)
        status = pg.gc_map_fine(MLI_lt_masked_tmp_name, REF_MLI_width, diff_par_name, MLI_lt_masked_name)
        check_output(status, error_flag, cleaning, tmp_dir)
    
      else:
        shutil.copyfile(MLI_lt_name, MLI_lt_tmp_name)
        status = pg.gc_map_fine(MLI_lt_tmp_name, REF_MLI_width, diff_par_name, MLI_lt_name)
        check_output(status, error_flag, cleaning, tmp_dir)
        shutil.copyfile(MLI_lt_name, MLI_lt_masked_name)
        
      quality = open(quality_name, "a+")
      
      if matching_fail:
        quality.write("\nmatching iteration %d has failed\n" %(it))
      else:
        quality.write("\nmatching iteration %d:\n" %(it))
        quality.write("daz = %f + %e*r + %e*az + %e*r*az + %e*r*r + %e*az*az\n" %(daz_list[0], daz_list[1], daz_list[2], daz_list[3], daz_list[4], daz_list[5]))
        quality.write("dr = %f + %e*r + %e*az + %e*r*az + %e*r*r + %e*az*az\n" %(dr_list[0], dr_list[1], dr_list[2], dr_list[3], dr_list[4], dr_list[5]))
        quality.write("stdev: %f %f (azimuth_stdev range_stdev)\n" %(azimuth_stdev, range_stdev))
        quality.write("daz_mli = %f + %e*r + %e*az + %e*r*az + %e*r*r + %e*az*az\n" %(daz_list_mli[0], daz_list_mli[1], daz_list_mli[2], daz_list_mli[3], daz_list_mli[4], daz_list_mli[5]))
        quality.write("dr_mli = %f + %e*r + %e*az + %e*r*az + %e*r*r + %e*az*az\n" %(dr_list_mli[0], dr_list_mli[1], dr_list_mli[2], dr_list_mli[3], dr_list_mli[4], dr_list_mli[5]))
      quality.close()
      
  else:
    quality = open(quality_name, "a+")
    quality.write("\nNo iterative improvement of refinement offset using intensity matching\n")
    quality.close()
  
  # Iterative improvement of azimuth refinement using spectral diversity method
  if (max_it2 > 0):
    
    # mask for polygon region poly2 that is at the same time part of the burst overlap regions
    if (poly_mask_flag):
      status = pg.ScanSAR_burst_overlap(SLC1_tab_name, az_ovr_root_name, rlks, azlks, 4, '-', '-', '-', poly_bound)
      check_output(status, error_flag, cleaning, tmp_dir)
      
      if poly2_flag:
        status = pg.poly_mask(MLI_lt_name, MLI_lt_az_ovr_tmp_name, REF_MLI_width, az_ovr_poly_name, 0, 1)
        check_output(status, error_flag, cleaning, tmp_dir)
        status = pg.poly_mask(MLI_lt_az_ovr_tmp_name, MLI_lt_az_ovr_name, REF_MLI_width, poly2_name, 0, 1)
        check_output(status, error_flag, cleaning, tmp_dir)
      
      else:
        status = pg.poly_mask(MLI_lt_name, MLI_lt_az_ovr_name, REF_MLI_width, az_ovr_poly_name, 0, 1)
        check_output(status, error_flag, cleaning, tmp_dir)
  
    else:
      shutil.copyfile(MLI_lt_name, MLI_lt_az_ovr_name)
  
    quality = open(quality_name, "a+")
    quality.write("\nIterative improvement of refinement offset azimuth overlap regions:\n\n")
    quality.close()

    # iterate while azimuth correction > 0.0005 SLC pixel or maximum number of iterations has been reached
    it = 0
    daz = 1
    while ((abs(daz) > 0.0005) and (it < max_it2)):
      # increase iteration counter
      it = it + 1
      print("offset refinement using spectral diversity iteration %d" %it)

      shutil.copyfile(off_par_name, off_par_start_name)
  
      status = pg.SLC_interp_lt_ScanSAR(SLC2_tab_name, SLC_par_name, SLC1_tab_name, REF_SLC_par_name, MLI_lt_az_ovr_name, REF_MLI_par_name, MLI_par_name, off_par_start_name, RSLC2_tab_name, RSLC_name, RSLC_par_name, logf = log2_name, stdout_flag = False)
      check_output(status, error_flag, cleaning, tmp_dir)
      
      az_ovr_log.append("%s/%s.off.az_ovr.%d.out" %(tmp_dir, pair_name, it))
      if os.path.isfile(az_ovr_log[it-1]):
        os.remove(az_ovr_log[it-1])
      az_ovr_list = []
      
      if (RSLC3_flag and RSLC3_ID != ''):
        if (cleaning):
          status = pg.ScanSAR_coreg_overlap(SLC1_tab_name, RSLC2_tab_name, pair_name, off_par_start_name, off_par_name, '--cc', cc_thresh, '--fraction', fraction_thresh, '--ph_stdev', stdev_thresh, '--num_ovr', max_num_ovr, '--RSLC3_tab', RSLC3_tab_name, '--wdir', wdir, logf = az_ovr_log[it-1], cout = az_ovr_list, stdout_flag = False)
        else:
          status = pg.ScanSAR_coreg_overlap(SLC1_tab_name, RSLC2_tab_name, pair_name, off_par_start_name, off_par_name, '--cc', cc_thresh, '--fraction', fraction_thresh, '--ph_stdev', stdev_thresh, '--num_ovr', max_num_ovr, '--RSLC3_tab', RSLC3_tab_name, '--wdir', wdir, '--no_cleaning', logf = az_ovr_log[it-1], cout = az_ovr_list, stdout_flag = False)
      else:
        if (cleaning):
          status = pg.ScanSAR_coreg_overlap(SLC1_tab_name, RSLC2_tab_name, pair_name, off_par_start_name, off_par_name, '--cc', cc_thresh, '--fraction', fraction_thresh, '--ph_stdev', stdev_thresh, '--num_ovr', max_num_ovr, '--wdir', wdir, logf = az_ovr_log[it-1], cout = az_ovr_list, stdout_flag = False)
        else:
          status = pg.ScanSAR_coreg_overlap(SLC1_tab_name, RSLC2_tab_name, pair_name, off_par_start_name, off_par_name, '--cc', cc_thresh, '--fraction', fraction_thresh, '--ph_stdev', stdev_thresh, '--num_ovr', max_num_ovr, '--wdir', wdir, '--no_cleaning', logf = az_ovr_log[it-1], cout = az_ovr_list, stdout_flag = False)
      
      check_output(status, error_flag, cleaning, tmp_dir)
        
      for item in az_ovr_list:
        if "avg_azimuth_pixel_offset" in item:
          line = item.split(":")
          daz = float(line[1].strip())

      shutil.copyfile(off_par_name, "%s/%s.off.%d" %(tmp_dir, pair_name, it))
      
      quality = open(quality_name, "a+")
      if it == 0:
        daz = daz - daz_value_icc # ML, see above
      quality.write("az_ovr iteration %d: %f (daz in SLC pixel)\n" %(it, daz))
      results = open(results_name, "r")
      for line in results:
        quality.write("%s" %(line))
      results.close()
      quality.write("\n")
      quality.close()
      
  else:
    quality = open(quality_name, "a+")
    quality.write("\nNo Iterative improvement of refinement offset using azimuth overlap regions\n")
    quality.close()
  
  # resample full data set
  status = pg.SLC_interp_lt_ScanSAR(SLC2_tab_name, SLC_par_name, SLC1_tab_name, REF_SLC_par_name, MLI_lt_name, REF_MLI_par_name, MLI_par_name, off_par_name, RSLC2_tab_name, RSLC_name, RSLC_par_name, logf = log3_name, stdout_flag = False)
  check_output(status, error_flag, cleaning, tmp_dir)
  
  # generate differential interferogram (also for testing for jumps at burst overlaps)
  if (int_flag):
    # topographic phase simulation 
    if (flag1 and os.path.isfile(sim_unw_name)):
      print("using existing simulated phase: %s " %(sim_unw_name))
    else:
      if (hgt_file_flag):
        status = pg.phase_sim_orb(REF_SLC_par_name, SLC_par_name, off_par_name, hgt_name, sim_unw_name, REF_SLC_par_name, '-', '-', 1, 1)
        check_output(status, error_flag, cleaning, tmp_dir)
      
      else:
        status = pg.phase_sim_orb(REF_SLC_par_name, SLC_par_name, off_par_name, '-', sim_unw_name, REF_SLC_par_name, '-', '-', 1, 1)
        check_output(status, error_flag, cleaning, tmp_dir)
   
    # calculation of a ScanSAR differential interferogram
    status = pg.SLC_diff_intf(REF_SLC_name, RSLC_name, REF_SLC_par_name, RSLC_par_name, off_par_name, sim_unw_name, diff_name, rlks, azlks, 1, 0, 0.2, 1, 1)
    check_output(status, error_flag, cleaning, tmp_dir)
      
    status = pg.rasmph_pwr(diff_name, REF_MLI_name, REF_MLI_width, '-', '-', '-', '-', '-', diff_ras_name)
    check_output(status, error_flag, cleaning, tmp_dir)
    
    quality = open(quality_name, "a+")
    quality.write("\n")
    quality.write("Generated differential interferogram: %s\n" %(diff_name))
    quality.write("to display use:   eog %s &\n" %(diff_ras_name))
    quality.close()
    
    # generate the differential interferogram with the $RSLC3_ID scene
    if (RSLC3_flag and RSLC3_ID != ''):
      if (flag1 and os.path.isfile(RSLC3_name) and os.path.isfile(RSLC3_par_name)):
        print("using existing SLC mosaic of already co-registered ScanSAR second scene: %s %s" %(RSLC3_name, RSLC3_par_name))
      else:
        status = pg.SLC_mosaic_ScanSAR(RSLC3_tab_name, RSLC3_name, RSLC3_par_name, rlks, azlks, 0, SLC1_tab_name)
        check_output(status, error_flag, cleaning, tmp_dir)
      
      if (flag1 and os.path.isfile(RMLI3_name) and os.path.isfile(RMLI3_par_name)):
        print("using existing MLI mosaic of already co-registered ScanSAR second scene: %s %s" %(RMLI3_name, RMLI3_par_name))
      else:
        status = pg.multi_look(RSLC3_name, RSLC3_par_name, RMLI3_name, RMLI3_par_name, rlks, azlks)
        check_output(status, error_flag, cleaning, tmp_dir)
      
      # topographic phase simulation 
      if (flag1 and os.path.isfile(sim_unw3_name)):
        print("using existing simulated phase: %s " %(sim_unw3_name))
      else:
        if (hgt_file_flag):
          status = pg.phase_sim_orb(RSLC3_par_name, SLC_par_name, off_par_name, hgt_name, sim_unw3_name, REF_SLC_par_name, '-', '-', 1, 1)
          check_output(status, error_flag, cleaning, tmp_dir)
        
        else:
          status = pg.phase_sim_orb(RSLC3_par_name, SLC_par_name, off_par_name, '-', sim_unw3_name, REF_SLC_par_name, '-', '-', 1, 1)
          check_output(status, error_flag, cleaning, tmp_dir)
      
      # calculation of a ScanSAR differential interferogram
      status = pg.SLC_diff_intf(RSLC3_name, RSLC_name, RSLC3_par_name, RSLC_par_name, off_par_name, sim_unw3_name, diff3_name, rlks, azlks, 1, 0, 0.2, 1, 1)
      check_output(status, error_flag, cleaning, tmp_dir)
      
      status = pg.rasmph_pwr(diff3_name, RMLI3_name, REF_MLI_width, '-', '-', '-', '-', '-', diff3_ras_name)
      check_output(status, error_flag, cleaning, tmp_dir)
      
      quality = open(quality_name, "a+")
      quality.write("\n")
      quality.write("Generated differential interferogram: %s\n" %(diff3_name))
      quality.write("to display use:   eog %s &\n" %(diff3_ras_name))
      quality.close()
  
  if cleaning:
    try:
      shutil.rmtree(tmp_dir)
    except OSError:
      print("\nDeletion of the directory %s failed" % tmp_dir)
    else:
      print("\nSuccessfully deleted the directory %s" % tmp_dir)
    
  t_end = datetime.datetime.now()
  delta_t = t_end - t_cur
  print("\nend of ScanSAR_coreg.py, elapsed time (s): %s\n" %(str(delta_t.total_seconds())))
  
  quality = open(quality_name, "a+")
  quality.write("\n")
  quality.write("end of ScanSAR_coreg.py\n")
  quality.write("%s\n\n" %(str(t_end)))
  quality.close()

  return 0

if __name__ == "__main__":
  main()
  
